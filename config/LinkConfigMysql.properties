#################################
#                               #
#   Data Source Configuration   #
#                               #
#################################

# Implementation of LinkStore and NodeStore to use 
linkstore = com.facebook.LinkBench.LinkStoreMysql
nodestore = com.facebook.LinkBench.LinkStoreMysql

# mysql configuration
host = yourhostname.here
user = mysqluser
password = mysqlpass
dbid = linkdb
port = 3306

###############################
#                             #
#   Benchmark Configuration   #
#                             #
###############################

linktable = linktable

nodetable = nodetable

# ignore counttable if not using mysql
counttable = counttable

# This controls logging output.  Settings are, in order of increasing
# verbosity:
# ERROR: only output serious errors
# WARN: output warnings
# INFO: output additional information such as progress
# DEBUG: output high-level debugging information
# TRACE: output more detailed lower-level debugging information
debuglevel = INFO

# number of threads to run during load phase
loaders = 10
# partition loading work into chunks of id1s of this size
loader_chunk_size = 2048

# number of threads to run during request phase
requesters = 100

# id1 at which to start (inclusive)
startid1 = 1

# id1 at which to stop (exclusive);
maxid1 = 10000001

# whether to generate graph nodes during load process
generate_nodes = true

# if nonzero, generate id2 randomly between 0 and this - 1 during load
# and lookups. Caution - this needs to be <= max 32 bit integer in java
randomid2max = 0

# configuration for generating id2 in the request phase
# 0 means thread i generates id2 randomly without restriction;
# 1 means thread i generates id2 such that id2 % nrequesters = i,
#   this is to prevent threads from adding/deleting/updating same cells,
#   always use this configuration (1) when using HBaseGeneralAtomicityTesting;
id2gen_config = 0

# seed for initial data load random number generation (optional)
# load_random_seed = 12345

# seed for request random number generation (optional)
# request_random_seed = 12345

# read + write requests per thread
requests = 500000

# request rate per thread.  <= 0 means unthrottled requests, > 0 limits
#  the average request rate to that number of requests per second per thread,
#  with the inter-request intervals governed by an exponential distribution
requestrate = 0

# maximum number of failures per requester to tolerate before aborting
# negative number means never abort
max_failed_requests = 0

# max duration in seconds for the 2nd part of benchmark (1st part is load)
maxtime = 3600

# percentage split of requdests into addlink, deletelink, updatelink,
# getlink (point look-up), getlinklist (range look-up), countlinks.
# need to add up to 100
# Caution: countlink, getlink and getlinklist should be set to 0 when
#   using HBaseGeneralAtomictityTesting
# an exception will be thrown in case of failure to do so
addlink = 4.7134474362
deletelink = 0.6567126524
updatelink = 3.3448509064
countlink = 21.0929379261
getlink = 1.3015403725
getlinklist = 68.8905107064
addnode = 0.0
updatenode = 0.0
deletenode = 0.0
getnode = 0.0

# Controls what proportion of linklist queries above will try
# to retrieve more history of a long list
getlinklist_history = 5.0

# stats on timetaken displayed after this many seconds (min, max etc)
displayfreq = 1800

# display short progress update after this many seconds (not full stats) 
progressfreq = 300

# if number of operations is > this, we store timetaken only for this many
# operations
maxsamples = 10000

# Configure payload data generation
# Median # bytes to put in link 'data' field
link_datasize = 6.85
# Data generation classes and parameters for that class
link_add_datagen = com.facebook.LinkBench.generators.UniformDataGenerator
link_add_datagen_startbyte = 97
link_add_datagen_endbyte = 100
link_up_datagen = com.facebook.LinkBench.generators.UniformDataGenerator
link_up_datagen_startbyte = 101
link_up_datagen_endbyte = 104

# Median data size of nodes
node_datasize = 97.9
# Data generation classes and parameters for that class
node_add_datagen = com.facebook.LinkBench.generators.UniformDataGenerator
node_add_datagen_startbyte = 0
node_add_datagen_endbyte = 255
node_up_datagen = com.facebook.LinkBench.generators.UniformDataGenerator
node_up_datagen_startbyte = 0
node_up_datagen_endbyte = 255

# Number of distinct link types (links are distributed among the types)
link_type_count = 1

# #links distribution function
# RECIPROCAL means small id1s tend to get more #links : 
#          #links(id1) = maxid1/(1+id1)
# MULTIPLES means id1s that are multiples of nlinks_config get 
#   nlinks_config links
#   (rest get nlinks_default)
# PERFECT_POWERS means perfect squares/cubes/etc get more #links 
#   (rest get nlinks_default)
#   the larger a perfect square is, the more #links it gets.
#   nlinks_config controls whether it is squares, cubes, etc
# EXPONENTIAL means exponential i.e powers of nlinks_config get more #links
# REAL means use the empirically observed distribution in the data file
# Otherwise you can provide a class name implementing ProbabilityDistribution
# and any other parameters for that class with the nlinks_ prefix
nlinks_func = real
#config param that goes along with nlinks_func
nlinks_config = 1
# use 0 or 1 for this
nlinks_default = 0

# Example: use Zipf for nlinks with scale and shape params
#nlinks_func = = com.facebook.LinkBench.distributions.ZipfDistribution
#nlinks_shape = 1.5
# mean # links per id 
#nlinks_mean = 2000000

# read/write distributions
# function options are:
# An arbitrary ProbabilityDistribution class (e.g. ZipfDistribution)
#    REAL - Real empirical distribution for reads/writes as appropriate
#    ROUND_ROBIN - Cycle through ids
#    RECIPROCAL - Pick with probability 
#    MULTIPLE - Pick a multiple of config parameter
#    POWER - Pick a power of config parameter
#    PERFECT_POWER - Pick a perfect power (square, cube, etc) with exponent
#                    as configured

# read function and config param
read_function = REAL

# Optionally, mix in a read function uncorrelated with outdegree
# blend: % of link reads to use uncorrelated func for
read_uncorr_blend = 0.0
read_uncorr_function = REAL

# write function and config param
write_function = REAL
write_config = 1

# Optionally, mix in a write function uncorrelated with outdegree
# blend: % of link writes to use uncorrelated func for
write_uncorr_blend = 0.0
write_uncorr_function = REAL

# Access distributions for graph nodes (a class name implementing the
# ProbabilityDistribution interface)
node_read_function = com.facebook.LinkBench.distributions.ZipfDistribution
#node_read_function = REAL
# Shape parameter for Zipf
node_read_shape = 0.8
node_update_function = com.facebook.LinkBench.distributions.ZipfDistribution
#node_update_function = REAL
# Shape parameter for Zipf
node_update_shape = 0.8

# Use uniform rather than skewed distribution for deletes, because:
# a) we don't want to delete the most frequently read nodes
# b) nodes can only be deleted once
node_delete_function = com.facebook.LinkBench.distributions.UniformDistribution

# Distribution to select how many ids per link get request.  Comment
# out to disable multigets (i.e. use id2 per request).
link_multiget_dist = com.facebook.LinkBench.distributions.GeometricDistribution
link_multiget_dist_min = 1
link_multiget_dist_max = 128
# Parameter for geometric distribution approximating real distribution
link_multiget_dist_prob = 0.382


data_file = config/Distribution.dat

###############################
#                             #
#   MySql Configuration       #
#                             #
###############################

# Optional tuning parameters

# # of link inserts to batch together when loading
# mysql_bulk_insert_batch = 1024

# optional tuning - disable binary logging during load phase
# WARNING: do not use unless you know what you are doing, it can
# break replication amongst other things
# mysql_disable_binlog_load = true

